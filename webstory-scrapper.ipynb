{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "import urllib.request\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"best.txt\",\"r\")\n",
    "links=(file1.readlines()) \n",
    "for i in range(len(links)):\n",
    "    links[i]=links[i].replace(\"\\n\",\"\")\n",
    "print(len(links),type(links[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=[]\n",
    "for i in range(len(links)):\n",
    "    d={}\n",
    "    Web_url = links[i]\n",
    "    r = requests.get(Web_url)\n",
    "    soup = BeautifulSoup(r.content, 'html5lib')\n",
    "    meta=soup.findAll('meta',{'property':['og:description','og:title','og:url']})\n",
    "    d['content']=meta[0].get('content')\n",
    "    d['title']=meta[1].get('content')\n",
    "    url=meta[2].get('content')\n",
    "    url=list(url.split('/'))\n",
    "    d['url']=url[-2]\n",
    "    print(d)\n",
    "    output.append(d)\n",
    "json_dump=json.dumps(output)\n",
    "file_name=\"title-description.json\"\n",
    "with open(file_name, \"w\") as outfile:\n",
    "    outfile.write(json_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(links)):\n",
    "    Web_url = links[i]\n",
    "    print(Web_url)\n",
    "    r = requests.get(Web_url)\n",
    "    webstoryno=i+1\n",
    "    os.makedirs(\"webstory-\"+str(webstoryno))\n",
    "    soup = BeautifulSoup(r.content, 'html5lib')\n",
    "    stories=soup.findAll('amp-story-page')\n",
    "    output=[]\n",
    "    items=0\n",
    "    for st in stories:\n",
    "        story={}\n",
    "        story['url']=Web_url.split('/')[-2]\n",
    "        headings=(st.findAll('h1'))\n",
    "        subheadings=(st.findAll('h2'))\n",
    "        paras=(st.findAll('p'))\n",
    "        story['heading']=[]\n",
    "        for heading in headings:\n",
    "            story['heading'].append(heading.text)\n",
    "        story['subheading']=[]\n",
    "        for subheading in subheadings:\n",
    "            story['subheading'].append(subheading.text)\n",
    "        story['para']=[]\n",
    "        for para in paras:\n",
    "            story['para'].append(para.text)\n",
    "        image=st.find('amp-img')\n",
    "        poster=st.find('amp-video')\n",
    "        video=st.findAll('source')\n",
    "        story['image']=\"\"\n",
    "        story['poster']=\"\"\n",
    "        story['video']=\"\"\n",
    "        if image:\n",
    "            items+=1\n",
    "            src=image['src']\n",
    "            img_src=src\n",
    "            src=list(src.split('/'))\n",
    "            src=\"webstory-\"+str(webstoryno)+\"-\"+src[-1]\n",
    "            story['image']=src\n",
    "            src=\"webstory-\"+str(webstoryno)+'/'+src\n",
    "            try:\n",
    "                urllib.request.urlretrieve(img_src,src)\n",
    "            except:\n",
    "                print(img_src,src,webstoryno)\n",
    "        if poster:\n",
    "            items+=1\n",
    "            src=poster['poster']\n",
    "            post_src=src\n",
    "            src=list(src.split('/'))\n",
    "            src=\"webstory-\"+str(webstoryno)+\"-\"+src[-1]\n",
    "            story['poster']=src\n",
    "            src=\"webstory-\"+str(webstoryno)+'/'+src\n",
    "            try:\n",
    "                urllib.request.urlretrieve(post_src,src)\n",
    "            except:\n",
    "                print(post_src,src,webstoryno)\n",
    "        if video:\n",
    "            items+=1\n",
    "            src=video[-1]['src']\n",
    "            video_src=src\n",
    "            src=list(src.split('/'))\n",
    "            src=\"webstory-\"+str(webstoryno)+\"-\"+src[-1]\n",
    "            story['video']=src\n",
    "            src=\"webstory-\"+str(webstoryno)+'/'+src\n",
    "            try:\n",
    "                urllib.request.urlretrieve(video_src,src)\n",
    "            except:\n",
    "                print(video_src,src,webstoryno)\n",
    "        output.append(story)\n",
    "    print(\"No of items:\",items+1)\n",
    "    json_dump=json.dumps(output)\n",
    "    file_name=\"webstory-\"+str(webstoryno)+'/'+\"webstory-\"+str(webstoryno)+\".json\"\n",
    "    with open(file_name, \"w\") as outfile:\n",
    "        outfile.write(json_dump)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31dcc24e3ac10d8403f8c2f787b2a62350a3bf6c052852407c7fad78b9c5c78d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
